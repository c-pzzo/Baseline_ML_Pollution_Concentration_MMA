{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1972762e",
   "metadata": {},
   "source": [
    "# About\n",
    "Hyperparameter optimization is required to get the most out of your machine learning models.\n",
    "\n",
    "Hyperparameters are points of choice or configuration that allow a machine learning model to be customized for a specific task or dataset.\n",
    "\n",
    "Parameters are different from hyperparameters. Parameters are learned automatically; hyperparameters are set manually to help guide the learning process.\n",
    "\n",
    "Choosing a hyperparameter grid is probably the most difficult part of hyperparameter tuning: it's nearly impossible ahead of time to say which values of hyperparameters will work well and the optimal settings will depend on the dataset. Moreover, the hyperparameters have complex interactions with each other which means that just tuning one at a time doesn't work because when we start changing other hyperparameters that will affect the one we just tuned!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b78e61",
   "metadata": {},
   "source": [
    "! https://practicaldatascience.co.uk/machine-learning/how-to-use-model-selection-and-hyperparameter-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b72428",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d4cf86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User information is ready!\n"
     ]
    }
   ],
   "source": [
    "%run \"/home/cesar/Python_NBs/HDL_Project/HDL_Project/global_fv.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f177fd95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/cesar/Python_NBs/HDL_Project/HDL_Project/2_Models/Multivariate/ML'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "\n",
    "# Save trained models\n",
    "import joblib\n",
    "\n",
    "# Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "\n",
    "# Hypertuning tools\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import SCORERS\n",
    "\n",
    "# Nonlinear models\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "# Ensemble models\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Clone of time class\n",
    "s = t\n",
    "\n",
    "# Random seed\n",
    "np.random.seed(101)\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69844e52",
   "metadata": {},
   "source": [
    "# User-Defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27563f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_tuning(name, model, space, X, y):\n",
    "    # The searching algorithm includes a “cv” argument that allows:\n",
    "    # a) An integer number of folds to be specified, e.g. 5\n",
    "    #cross_val = 5\n",
    "    # b) A configured cross-validation object.\n",
    "    kfold = KFold(n_splits=3, shuffle=False)\n",
    "\n",
    "    # The scoring metric must be maximizing, meaning better models result in larger scores.\n",
    "    scoring_metric = 'neg_mean_squared_error'\n",
    "\n",
    "    # Search for best hyperparameters\n",
    "    grid = RandomizedSearchCV(estimator=model, \n",
    "                              param_distributions=search_space, \n",
    "                              cv=kfold, \n",
    "                              n_iter=100,\n",
    "                              scoring=scoring_metric)\n",
    "\n",
    "    result = grid.fit(X_test, y_test)\n",
    "    \n",
    "    # Save the trained model\n",
    "    filename = 'trained_ml_models_mvi/{}.sav'.format(name)\n",
    "    joblib.dump(result, filename)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d253219f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate a single model\n",
    "def single_model_evaluation(X_test, y_test, name):\n",
    "    # Load the trained model\n",
    "    filename = 'trained_ml_models_mvi/{}.sav'.format(name)\n",
    "    model = joblib.load(filename)\n",
    "\n",
    "    # make predictions\n",
    "    y_prediction = model.predict(X_test)\n",
    "    \n",
    "    metrics = dict()\n",
    "    # evaluate predictions\n",
    "    metrics[\"RMSE\"] = mean_squared_error(y_test, y_prediction, squared=False)\n",
    "    metrics[\"MAE\"] = mean_absolute_error(y_test, y_prediction)\n",
    "    metrics[\"MAPE (%)\"] = mean_absolute_percentage_error(y_test, y_prediction) *100\n",
    "    metrics[\"R^2 (%)\"] = r2_score(y_test, y_prediction) * 100\n",
    "    metrics[\"Max Error\"] = max_error(y_test, y_prediction)    \n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cacf94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "filename = 'trained_ml_models_mvi/{}.sav'.format(\"KNN\")\n",
    "model = joblib.load(filename)\n",
    "\n",
    "# make predictions\n",
    "y_prediction = model.predict(X_test)\n",
    "\n",
    "metrics = dict()\n",
    "# evaluate predictions\n",
    "metrics[\"RMSE\"] = mean_squared_error(y_test, y_prediction, squared=False)\n",
    "metrics[\"MAE\"] = mean_absolute_error(y_test, y_prediction)\n",
    "metrics[\"MAPE (%)\"] = mean_absolute_percentage_error(y_test, y_prediction) *100\n",
    "metrics[\"R^2 (%)\"] = r2_score(y_test, y_prediction) * 100\n",
    "metrics[\"Max Error\"] = max_error(y_test, y_prediction)    \n",
    "\n",
    "print(y_prediction)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7660cd23",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c08cdff",
   "metadata": {},
   "source": [
    "## Sample preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d22dc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_table = \"MVI_sima_station_CE\"\n",
    "target = \"pm25\"\n",
    "\n",
    "# Define columns of interest from sql table\n",
    "#     Select all columns:\n",
    "column = \"*\"\n",
    "#     Select specific columns:\n",
    "#column = \"datetime, prs, rainf, rh, sr, tout, wdr, wsr, \" + str(target)\n",
    "\n",
    "# Filter data with WHERE command\n",
    "sql_where = \"where datetime >=\\'2021-04-17 23:00:00\\'\"\n",
    "#\"where datetime > \\'2020-04-20\\'\"\n",
    "\n",
    "# Initialize class to create multivariate samples:\n",
    "multi_ts = multivariate_samples(sql_table, target, column, sql_where)\n",
    "\n",
    "# Datasets can't be trained with sample batches by default. So parameter is 1.\n",
    "X, y, _ = multi_ts.samples_creation(1, target)\n",
    "\n",
    "# Training and test datasets are prepared, avoiding shuffling because it is a time series.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[:,0,:], y, test_size = 0.30, shuffle= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b56c7073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'continuous'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_of_target(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f7bd2f",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b04d179",
   "metadata": {},
   "source": [
    "## Objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1adcfceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorted(SCORERS.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa61ce7",
   "metadata": {},
   "source": [
    "# Random Search\n",
    "RandomizedSearchCV for random search evaluates models for a given hyperparameter vector using cross-validation, hence the “CV” suffix of each class name.\n",
    "\n",
    "It requires two arguments. \n",
    "1. The first is the model that you are optimizing. This is an instance of the model with values of hyperparameters set that you want to optimize. \n",
    "2. The second is the search space. This is defined as a dictionary where the names are the hyperparameter arguments to the model and the values are discrete values or a distribution of values to sample in the case of a random search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f606afc",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors\n",
    "KNeighborsRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb794f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'auto',\n",
       " 'leaf_size': 30,\n",
       " 'metric': 'minkowski',\n",
       " 'metric_params': None,\n",
       " 'n_jobs': None,\n",
       " 'n_neighbors': 5,\n",
       " 'p': 2,\n",
       " 'weights': 'uniform'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select an algorithm\n",
    "model = KNeighborsRegressor()\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0750b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search space\n",
    "search_space = [{\n",
    "    'n_neighbors': list(range(1,10)),\n",
    "    'weights': list(['uniform', 'distance']),\n",
    "    'algorithm': list(['auto', 'ball_tree', 'kd_tree', 'brute']),\n",
    "    'leaf_size': list(range(15, 45)),\n",
    "    'p': list([1,2]),\n",
    "    'metric': list(['euclidean', 'manhattan','chebyshev', 'minkowski']),\n",
    "    # The search can be made parallel using various if not all of your CPU cores \n",
    "    # We can set it to -1 to automatically use all of the cores in the system.\n",
    "    'n_jobs': list([-1])\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bafdedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 6.124174 seconds.\n",
      "-126.0946106700254\n",
      "\n",
      "KNeighborsRegressor(algorithm='kd_tree', leaf_size=18, n_jobs=-1, n_neighbors=9,\n",
      "                    p=1, weights='distance')\n",
      "\n",
      "{'weights': 'distance', 'p': 1, 'n_neighbors': 9, 'n_jobs': -1, 'metric': 'minkowski', 'leaf_size': 18, 'algorithm': 'kd_tree'}\n"
     ]
    }
   ],
   "source": [
    "t.tic()\n",
    "result_KNN = hyper_tuning(\"KNN\", model, search_space, X_train, y_train)\n",
    "t.toc(restart=True)\n",
    "# Get the results\n",
    "print(result_KNN.best_score_)\n",
    "print(\"\")\n",
    "print(result_KNN.best_estimator_)\n",
    "print(\"\")\n",
    "print(result_KNN.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297245af",
   "metadata": {},
   "source": [
    "## Classification and Regression Tree\n",
    "DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b303d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0,\n",
       " 'criterion': 'squared_error',\n",
       " 'max_depth': None,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'random_state': None,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select an algorithm\n",
    "model = DecisionTreeRegressor()\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94ce5735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search space\n",
    "search_space = [{\n",
    "    'criterion': list(['squared_error', 'friedman_mse', 'absolute_error', 'poisson'])\n",
    "    , 'splitter': list(['best', 'random'])\n",
    "    , 'max_depth': list(range(1,10))\n",
    "    , 'min_samples_split': list(range(2,10))\n",
    "    , 'min_samples_leaf': list(range(1,10))\n",
    "    , 'min_weight_fraction_leaf': list(np.linspace(0.0,0.5))\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32313cfa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 3.182892 seconds.\n",
      "-146.27069594910802\n",
      "\n",
      "DecisionTreeRegressor(criterion='friedman_mse', max_depth=9, min_samples_leaf=9,\n",
      "                      min_samples_split=7,\n",
      "                      min_weight_fraction_leaf=0.02040816326530612)\n",
      "\n",
      "{'splitter': 'best', 'min_weight_fraction_leaf': 0.02040816326530612, 'min_samples_split': 7, 'min_samples_leaf': 9, 'max_depth': 9, 'criterion': 'friedman_mse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cesar/anaconda3/envs/hdl_project/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "66 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "66 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cesar/anaconda3/envs/hdl_project/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/cesar/anaconda3/envs/hdl_project/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1315, in fit\n",
      "    super().fit(\n",
      "  File \"/home/cesar/anaconda3/envs/hdl_project/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 178, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Some value(s) of y are negative which is not allowed for Poisson regression.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/cesar/anaconda3/envs/hdl_project/lib/python3.8/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-172.97175012 -271.56022821           nan -213.6397853            nan\n",
      " -274.1872302            nan -268.2808189  -146.27069595 -221.430153\n",
      " -194.10290961 -151.0631386            nan -208.99731266           nan\n",
      " -235.85615195           nan -267.00114397 -188.72721157 -210.116628\n",
      " -228.12304557           nan -155.7429084  -211.9215996  -227.57631068\n",
      " -164.42112613 -212.51257554 -252.37776442 -182.92021576 -222.86160618\n",
      " -186.8415605  -222.59210653           nan -253.74182798           nan\n",
      " -213.6397853  -219.11165483 -286.96359194           nan           nan\n",
      " -199.36258736 -211.9215996            nan -233.60482139 -221.430153\n",
      " -197.45322539 -213.6397853            nan -286.96359194           nan\n",
      "           nan -151.7298658            nan -219.11165483           nan\n",
      " -200.65068509 -234.31537846 -213.6397853  -286.96359194 -252.79254875\n",
      "           nan -274.87650873 -168.52258703 -222.89877081 -171.37341522\n",
      "           nan -213.6397853            nan           nan           nan\n",
      "           nan -272.74415255 -186.24351558 -223.0205211  -171.07575004\n",
      "           nan           nan -269.29564641 -274.87650873 -262.17599888\n",
      " -207.0073152            nan -221.430153             nan -236.8805964\n",
      "           nan -219.11165483           nan -264.77792562           nan\n",
      "           nan -193.38131523 -194.3466799  -286.96359194 -235.91794518\n",
      " -159.72821938           nan -277.02182949           nan -233.96768527]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "t.tic()\n",
    "result_DTR = hyper_tuning(\"DecisionTrees\", model, search_space, X_train, y_train)\n",
    "t.toc(restart=True)\n",
    "\n",
    "# Get the results\n",
    "print(result_DTR.best_score_)\n",
    "print(\"\")\n",
    "print(result_DTR.best_estimator_)\n",
    "print(\"\")\n",
    "print(result_DTR.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8b3674",
   "metadata": {},
   "source": [
    "## Support Vector Regression - Polynomial\n",
    "svm.SVR(kernel='poly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cc46eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'cache_size': 200,\n",
       " 'coef0': 0.0,\n",
       " 'degree': 3,\n",
       " 'epsilon': 0.1,\n",
       " 'gamma': 'scale',\n",
       " 'kernel': 'rbf',\n",
       " 'max_iter': -1,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select an algorithm\n",
    "model = svm.SVR()\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abcdc107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search space\n",
    "search_space = [{\n",
    "    'kernel': list(['poly'])\n",
    "    # `degree` is a parameter used when kernel is set to ‘poly’.\n",
    "    , 'degree': list([0, 2, 3, 4, 5, 6])\n",
    "    # Gamma is a parameter for non linear hyperplanes. \n",
    "    # The higher the gamma value it tries to exactly fit the training data set\n",
    "    , 'gamma' : list([0.1, 1, 10, 100])\n",
    "    # C is the penalty parameter of the error term. \n",
    "    # It controls the trade off between smooth decision boundary and classifying the training points correctly.\n",
    "    , 'C': list([0.1, 1, 10, 100, 1000])\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4df7656f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if(False):\n",
    "    t.tic()\n",
    "    result_SVM_poly = hyper_tuning(\"SVR_Poly\", model, search_space, X_train, y_train)\n",
    "    t.toc(restart=True)\n",
    "\n",
    "    # Get the results\n",
    "    print(result_SVM_poly.best_score_)\n",
    "    print(\"\")\n",
    "    print(result_SVM_poly.best_estimator_)\n",
    "    print(\"\")\n",
    "    print(result_SVM_poly.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd31d89a",
   "metadata": {},
   "source": [
    "## Support Vector Regression - RBF\n",
    "svm.SVR(kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94870cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'cache_size': 200,\n",
       " 'coef0': 0.0,\n",
       " 'degree': 3,\n",
       " 'epsilon': 0.1,\n",
       " 'gamma': 'scale',\n",
       " 'kernel': 'rbf',\n",
       " 'max_iter': -1,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select an algorithm\n",
    "model = svm.SVR()\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf4a6d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search space\n",
    "search_space = [{\n",
    "    'kernel': list(['rbf'])\n",
    "    # Gamma is a parameter for non linear hyperplanes. \n",
    "    # The higher the gamma value it tries to exactly fit the training data set\n",
    "    , 'gamma' : list([0.1, 1, 10, 100])\n",
    "    # C is the penalty parameter of the error term. \n",
    "    # It controls the trade off between smooth decision boundary and classifying the training points correctly.\n",
    "    , 'C': list([0.1, 1, 10, 100, 1000])\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88de60fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cesar/anaconda3/envs/hdl_project/lib/python3.8/site-packages/sklearn/model_selection/_search.py:292: UserWarning: The total space of parameters 20 is smaller than n_iter=100. Running 20 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 28.680515 seconds.\n",
      "-85.89965613835875\n",
      "\n",
      "SVR(C=100, gamma=1)\n",
      "\n",
      "{'kernel': 'rbf', 'gamma': 1, 'C': 100}\n"
     ]
    }
   ],
   "source": [
    "t.tic()\n",
    "result_SVM_RBF = hyper_tuning(\"SVR_RBF\", model, search_space, X_train, y_train)\n",
    "t.toc(restart=True)\n",
    "\n",
    "# Get the results\n",
    "print(result_SVM_RBF.best_score_)\n",
    "print(\"\")\n",
    "print(result_SVM_RBF.best_estimator_)\n",
    "print(\"\")\n",
    "print(result_SVM_RBF.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c99691c",
   "metadata": {},
   "source": [
    "## Support Vector Regression - Linear\n",
    "svm.SVR(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d3c8aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'cache_size': 200,\n",
       " 'coef0': 0.0,\n",
       " 'degree': 3,\n",
       " 'epsilon': 0.1,\n",
       " 'gamma': 'scale',\n",
       " 'kernel': 'rbf',\n",
       " 'max_iter': -1,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select an algorithm\n",
    "model = svm.SVR()\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5c68ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search space\n",
    "search_space = [{\n",
    "    'kernel': list(['linear'])\n",
    "    # Gamma is a parameter for non linear hyperplanes. \n",
    "    # The higher the gamma value it tries to exactly fit the training data set\n",
    "    , 'gamma' : list([0.1, 1, 10, 100])\n",
    "    # C is the penalty parameter of the error term. \n",
    "    # It controls the trade off between smooth decision boundary and classifying the training points correctly.\n",
    "    , 'C': list([0.1, 1, 10, 100, 1000])\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b9d57d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cesar/anaconda3/envs/hdl_project/lib/python3.8/site-packages/sklearn/model_selection/_search.py:292: UserWarning: The total space of parameters 20 is smaller than n_iter=100. Running 20 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 17.232813 seconds.\n",
      "-100.96341745684497\n",
      "\n",
      "SVR(C=100, gamma=0.1, kernel='linear')\n",
      "\n",
      "{'kernel': 'linear', 'gamma': 0.1, 'C': 100}\n"
     ]
    }
   ],
   "source": [
    "t.tic()\n",
    "result_SVM_Linear = hyper_tuning(\"SVR_Linear\", model, search_space, X_train, y_train)\n",
    "t.toc(restart=True)\n",
    "\n",
    "# Get the results\n",
    "print(result_SVM_Linear.best_score_)\n",
    "print(\"\")\n",
    "print(result_SVM_Linear.best_estimator_)\n",
    "print(\"\")\n",
    "print(result_SVM_Linear.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639436d6",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1add929b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'criterion': 'squared_error',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select an algorithm\n",
    "model = RandomForestRegressor()\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7abf1537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search space\n",
    "search_space = [{\n",
    "    # `n_estimators` represents the number of trees in the forest. \n",
    "    # Usually the higher the number of trees the better to learn the data. It is also computationally expensive.\n",
    "    'n_estimators': list([100, 200, 300, 400, 500])\n",
    "    # `max_depth` represents the depth of each tree in the forest. \n",
    "    # The deeper the tree, the more splits it has and it captures more information about the data.\n",
    "    , 'max_depth': list(np.linspace(1, 32, 32, endpoint=True))\n",
    "    # `min_samples_split` represents the minimum number of samples required to split an internal node. \n",
    "    , 'min_samples_split': list([2, 3, 4, 5, 6, 7, 8, 9, 10]) # list(np.linspace(1, 1, 10, endpoint=True))\n",
    "    # `min_samples_leaf` The minimum number of samples required to be at a leaf node.\n",
    "    #, 'min_samples_leafs': list([1, 2, 4])\n",
    "    # `max_features`: Represents the number of features to consider when looking for the best split.\n",
    "    , 'max_features': list(range(1,X_train.shape[1]))\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0d9a3f2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 326.752128 seconds.\n",
      "-95.08136703129003\n",
      "\n",
      "RandomForestRegressor(max_depth=19.0, max_features=9, min_samples_split=8,\n",
      "                      n_estimators=200)\n",
      "\n",
      "{'n_estimators': 200, 'min_samples_split': 8, 'max_features': 9, 'max_depth': 19.0}\n"
     ]
    }
   ],
   "source": [
    "t.tic()\n",
    "result_RF = hyper_tuning(\"RandomForest\", model, search_space, X_train, y_train)\n",
    "t.toc(restart=True)\n",
    "\n",
    "# Get the results \n",
    "print(result_RF.best_score_)\n",
    "print(\"\")\n",
    "print(result_RF.best_estimator_)\n",
    "print(\"\")\n",
    "print(result_RF.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0447f052",
   "metadata": {},
   "source": [
    "## Extra-trees regressor\n",
    "ExtraTreesRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b5ae84e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'criterion': 'squared_error',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select an algorithm\n",
    "model = ExtraTreesRegressor()\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40ebe9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search space\n",
    "search_space = [{\n",
    "    # `n_estimators` represents the number of trees in the forest. \n",
    "    # Usually the higher the number of trees the better to learn the data. It is also computationally expensive.\n",
    "    'n_estimators': list([1, 2, 4, 8, 16, 32, 64, 100, 200])\n",
    "    , 'criterion': ['squared_error']\n",
    "    # `max_depth` represents the depth of each tree in the forest. \n",
    "    # The deeper the tree, the more splits it has and it captures more information about the data.\n",
    "    , 'max_depth': list(np.linspace(1, 32, 32, endpoint=True))\n",
    "    # `min_samples_split` represents the minimum number of samples required to split an internal node. \n",
    "    , 'min_samples_split': list([2, 3, 4, 5, 6, 7, 8, 9, 10]) # list(np.linspace(1, 1, 10, endpoint=True))\n",
    "    # `min_samples_leaf` The minimum number of samples required to be at a leaf node.\n",
    "    #, 'min_samples_leafs': list(np.linspace(0.1, 0.5, 5, endpoint=True))\n",
    "    # `max_features`: Represents the number of features to consider when looking for the best split.\n",
    "    , 'max_features': list(range(1,X_train.shape[1]))\n",
    "\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68a98b35",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 20.617258 seconds.\n",
      "-92.2642297906054\n",
      "\n",
      "ExtraTreesRegressor(max_depth=17.0, max_features=12)\n",
      "\n",
      "{'n_estimators': 100, 'min_samples_split': 2, 'max_features': 12, 'max_depth': 17.0, 'criterion': 'squared_error'}\n"
     ]
    }
   ],
   "source": [
    "t.tic()\n",
    "result_ETR = hyper_tuning(\"ExtraTrees\", model, search_space, X_train, y_train)\n",
    "t.toc(restart=True)\n",
    "\n",
    "# Get the results\n",
    "print(result_ETR.best_score_)\n",
    "print(\"\")\n",
    "print(result_ETR.best_estimator_)\n",
    "print(\"\")\n",
    "print(result_ETR.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b2096e",
   "metadata": {},
   "source": [
    "## XG Boost \n",
    "XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "410f4f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'reg:squarederror',\n",
       " 'base_score': None,\n",
       " 'booster': None,\n",
       " 'colsample_bylevel': None,\n",
       " 'colsample_bynode': None,\n",
       " 'colsample_bytree': None,\n",
       " 'gamma': None,\n",
       " 'gpu_id': None,\n",
       " 'importance_type': 'gain',\n",
       " 'interaction_constraints': None,\n",
       " 'learning_rate': None,\n",
       " 'max_delta_step': None,\n",
       " 'max_depth': None,\n",
       " 'min_child_weight': None,\n",
       " 'missing': nan,\n",
       " 'monotone_constraints': None,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'num_parallel_tree': None,\n",
       " 'random_state': None,\n",
       " 'reg_alpha': None,\n",
       " 'reg_lambda': None,\n",
       " 'scale_pos_weight': None,\n",
       " 'subsample': None,\n",
       " 'tree_method': None,\n",
       " 'validate_parameters': None,\n",
       " 'verbosity': None}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select an algorithm\n",
    "model = XGBRegressor()\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a21d4186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search space\n",
    "search_space = [{\n",
    "    'max_depth': [3, 5, 6, 10, 15, 20]\n",
    "    , 'learning_rate': [0.01, 0.1, 0.2, 0.3]\n",
    "    , 'subsample': np.arange(0.5, 1.0, 0.1)\n",
    "    , 'colsample_bytree': np.arange(0.4, 1.0, 0.1)\n",
    "    , 'colsample_bylevel': np.arange(0.4, 1.0, 0.1)\n",
    "    , 'n_estimators': [100, 500, 1000, 1500, 2000]\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "86644010",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 404.661776 seconds.\n",
      "-87.43927484514329\n",
      "\n",
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=0.4,\n",
      "             colsample_bynode=1, colsample_bytree=0.7, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.01, max_delta_step=0, max_depth=5,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=2000, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.5,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "\n",
      "{'subsample': 0.5, 'n_estimators': 2000, 'max_depth': 5, 'learning_rate': 0.01, 'colsample_bytree': 0.7, 'colsample_bylevel': 0.4}\n"
     ]
    }
   ],
   "source": [
    "t.tic()\n",
    "result_XGB = hyper_tuning(\"XGBoost\", model, search_space, X_train, y_train)\n",
    "t.toc(restart=True)\n",
    "\n",
    "# Get the results\n",
    "print(result_XGB.best_score_)\n",
    "print(\"\")\n",
    "print(result_XGB.best_estimator_)\n",
    "print(\"\")\n",
    "print(result_XGB.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00ad9bd",
   "metadata": {},
   "source": [
    "# Loading and evaluating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9f76c99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7fe6c921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate a dict of models {name:object}, returns {name:score}\n",
    "def multiple_model_evaluation(X_test, y_test, models_list):\n",
    "    metrics_df = pd.DataFrame()\n",
    "    \n",
    "    for name in models_list:\n",
    "        # evaluate the model\n",
    "        s.tic()\n",
    "        tmp_df = pd.DataFrame(single_model_evaluation(X_test, y_test, name), index=[0])\n",
    "        tmp_df.insert(0, \"Model Name\", name, True)\n",
    "        tmp_df.insert(0, \"Type\", \"ML\", True)\n",
    "        metrics_df = metrics_df.append(tmp_df)\n",
    "        print(\"> {}.\".format(name))\n",
    "        s.toc(restart=True)\n",
    "        \n",
    "    return metrics_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "33c72ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> KNN.\n",
      "Elapsed time is 0.081322 seconds.\n",
      "> DecisionTrees.\n",
      "Elapsed time is 0.005863 seconds.\n",
      "> SVR_RBF.\n",
      "Elapsed time is 0.317110 seconds.\n",
      "> SVR_Linear.\n",
      "Elapsed time is 0.153042 seconds.\n",
      "> RandomForest.\n",
      "Elapsed time is 0.115748 seconds.\n",
      "> ExtraTrees.\n",
      "Elapsed time is 0.079571 seconds.\n",
      "> XGBoost.\n",
      "Elapsed time is 0.238433 seconds.\n",
      "Elapsed time is 0.000695 seconds.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE (%)</th>\n",
       "      <th>R^2 (%)</th>\n",
       "      <th>Max Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ML</td>\n",
       "      <td>KNN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ML</td>\n",
       "      <td>DecisionTrees</td>\n",
       "      <td>9.509687</td>\n",
       "      <td>6.819189</td>\n",
       "      <td>31.090354</td>\n",
       "      <td>66.813768</td>\n",
       "      <td>75.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ML</td>\n",
       "      <td>SVR_RBF</td>\n",
       "      <td>7.328579</td>\n",
       "      <td>4.450548</td>\n",
       "      <td>16.945624</td>\n",
       "      <td>80.290980</td>\n",
       "      <td>80.340007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ML</td>\n",
       "      <td>SVR_Linear</td>\n",
       "      <td>9.622198</td>\n",
       "      <td>6.519342</td>\n",
       "      <td>27.533241</td>\n",
       "      <td>66.023857</td>\n",
       "      <td>78.242506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ML</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>3.947193</td>\n",
       "      <td>2.599079</td>\n",
       "      <td>11.206802</td>\n",
       "      <td>94.282552</td>\n",
       "      <td>49.621498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ML</td>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>0.843669</td>\n",
       "      <td>0.507079</td>\n",
       "      <td>2.582010</td>\n",
       "      <td>99.738802</td>\n",
       "      <td>8.430837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ML</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>3.567968</td>\n",
       "      <td>2.620707</td>\n",
       "      <td>11.941028</td>\n",
       "      <td>95.328380</td>\n",
       "      <td>21.826057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Type     Model Name      RMSE       MAE   MAPE (%)     R^2 (%)  Max Error\n",
       "0   ML            KNN  0.000000  0.000000   0.000000  100.000000   0.000000\n",
       "1   ML  DecisionTrees  9.509687  6.819189  31.090354   66.813768  75.633333\n",
       "2   ML        SVR_RBF  7.328579  4.450548  16.945624   80.290980  80.340007\n",
       "3   ML     SVR_Linear  9.622198  6.519342  27.533241   66.023857  78.242506\n",
       "4   ML   RandomForest  3.947193  2.599079  11.206802   94.282552  49.621498\n",
       "5   ML     ExtraTrees  0.843669  0.507079   2.582010   99.738802   8.430837\n",
       "6   ML        XGBoost  3.567968  2.620707  11.941028   95.328380  21.826057"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get model list\n",
    "models_list = [\"KNN\", \"DecisionTrees\", \"SVR_RBF\", \"SVR_Linear\", \"RandomForest\", \"ExtraTrees\", \"XGBoost\"]\n",
    "\n",
    "# evaluate models\n",
    "t.tic() #Start timer\n",
    "results = multiple_model_evaluation(X_test, y_test, models_list)\n",
    "t.toc() #Time elapsed since t.tic()\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "34f88f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.   12.   10.   ... 22.25 25.19 27.87]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'RMSE': 0.0, 'MAE': 0.0, 'MAPE (%)': 0.0, 'R^2 (%)': 100.0, 'Max Error': 0.0}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c422a1ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.  , 12.  , 10.  , ..., 22.25, 25.19, 27.87])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3842f166",
   "metadata": {},
   "source": [
    "# Sources:\n",
    "## Main \n",
    "https://practicaldatascience.co.uk/machine-learning/how-to-use-model-selection-and-hyperparameter-tuning\n",
    "\n",
    "\n",
    "* sklearn.model_selection.RandomizedSearchCV\n",
    "    - https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html \n",
    "    - https://scikit-learn.org/stable/modules/grid_search.html?highlight=randomsearchcv\n",
    "* sklearn.model_selection.KFold\n",
    "    - https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\n",
    "    - https://machinelearningmastery.com/k-fold-cross-validation/\n",
    "\n",
    "\n",
    "## Models\n",
    "* KNN\n",
    "    - https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html\n",
    "    - https://scikit-learn.org/stable/modules/generated/sklearn.metrics.DistanceMetric.html#sklearn.metrics.DistanceMetric\n",
    "* DecisionTreeRegressor()\n",
    "    - https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\n",
    "* pmdarima\n",
    "    - https://towardsdatascience.com/efficient-time-series-using-pythons-pmdarima-library-f6825407b7f0\n",
    "* SVM\n",
    "    - https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html?highlight=svm%20svr%20kernel%20poly\n",
    "    - https://medium.com/all-things-ai/in-depth-parameter-tuning-for-svc-758215394769\n",
    "* Random Forest\n",
    "    - https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "    - https://medium.com/all-things-ai/in-depth-parameter-tuning-for-random-forest-d67bb7e920d\n",
    "* XGBoost\n",
    "    - https://towardsdatascience.com/xgboost-fine-tune-and-optimize-your-model-23d996fab663\n",
    "    \n",
    "* Gaussian NB\n",
    "    - https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html\n",
    "    - https://medium.com/analytics-vidhya/how-to-improve-naive-bayes-9fa698e14cba\n",
    "    - https://www.analyticsvidhya.com/blog/2021/01/gaussian-naive-bayes-with-hyperpameter-tuning/\n",
    "    \n",
    "## Metrics\n",
    "* Metrics and scoring: quantifying the quality of predictions\n",
    "    - https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "    - https://openclassrooms.com/en/courses/6401081-improve-the-performance-of-a-machine-learning-model/6539936-improve-your-feature-selection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
